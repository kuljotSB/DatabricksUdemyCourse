{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70afc85b-40d8-4800-b23c-06b4251390fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Driver notebook\n",
    "\n",
    "This is an auto-generated notebook created by an AI Playground export. We generated three notebooks in the same folder:\n",
    "- [agent]($./agent): contains the code to build the agent.\n",
    "- [config.yml]($./config.yml): contains the configurations.\n",
    "- [**driver**]($./driver): logs, evaluate, registers, and deploys the agent.\n",
    "\n",
    "This notebook uses Mosaic AI Agent Framework ([AWS](https://docs.databricks.com/en/generative-ai/retrieval-augmented-generation.html) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/generative-ai/retrieval-augmented-generation)) to deploy the agent defined in the [agent]($./agent) notebook. The notebook does the following:\n",
    "1. Logs the agent to MLflow\n",
    "2. Evaluate the agent with Agent Evaluation\n",
    "3. Registers the agent to Unity Catalog\n",
    "4. Deploys the agent to a Model Serving endpoint\n",
    "\n",
    "## Prerequisities\n",
    "\n",
    "- Address all `TODO`s in this notebook.\n",
    "- Review the contents of [config.yml]($./config.yml) as it defines the tools available to your agent, the LLM endpoint, and the agent prompt.\n",
    "- Review and run the [agent]($./agent) notebook in this folder to view the agent's code, iterate on the code, and test outputs.\n",
    "\n",
    "## Next steps\n",
    "\n",
    "After your agent is deployed, you can chat with it in AI playground to perform additional checks, share it with SMEs in your organization for feedback, or embed it in a production application. See docs ([AWS](https://docs.databricks.com/en/generative-ai/deploy-agent.html) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/generative-ai/deploy-agent)) for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61029f24-0f9b-49b4-8626-fafcccfc44b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -qqqq databricks-agents mlflow langchain==0.2.16 langgraph-checkpoint==1.0.12  langchain_core langchain-community==0.2.16 langgraph==0.2.16 pydantic databricks_langchain\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bae70910-d560-4333-b154-d22624f91e44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85567199-c59e-4644-b4db-0f818d1b523c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Log the `agent` as an MLflow model\n",
    "Log the agent as code from the [agent]($./agent) notebook. See [MLflow - Models from Code](https://mlflow.org/docs/latest/models.html#models-from-code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3865ac3-bef6-46a1-b16c-052c2f0a952f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 12:10:31 WARNING mlflow.models.utils: The model file uses magic commands which have been commented out. To ensure your code functions correctly, make sure that it does not rely on these magic commands for correctness.\n/tmp/tmpgpaeid7c/model.py:332: FutureWarning: ``mlflow.langchain.output_parsers.ChatCompletionsOutputParser`` is deprecated. This method will be removed in a future release. Use ``mlflow.langchain.output_parser.ChatCompletionOutputParser`` instead.\n  agent = agent_with_raw_output | RunnableGenerator(wrap_output) | ChatCompletionsOutputParser()\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-d62d2718-7926-4fa9-91f6-cdecc3391974/lib/python3.10/site-packages/mlflow/langchain/output_parsers.py:46: FutureWarning: ``mlflow.models.rag_signatures.Message`` is deprecated. This method will be removed in a future release. Use ``mlflow.types.llm.ChatMessage`` instead.\n  choices=[ChainCompletionChoice(message=Message(role=\"assistant\", content=text))],\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-d62d2718-7926-4fa9-91f6-cdecc3391974/lib/python3.10/site-packages/mlflow/langchain/output_parsers.py:46: FutureWarning: ``mlflow.models.rag_signatures.ChainCompletionChoice`` is deprecated. This method will be removed in a future release. Use ``mlflow.types.llm.ChatChoice`` instead.\n  choices=[ChainCompletionChoice(message=Message(role=\"assistant\", content=text))],\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-d62d2718-7926-4fa9-91f6-cdecc3391974/lib/python3.10/site-packages/mlflow/langchain/output_parsers.py:45: FutureWarning: ``mlflow.models.rag_signatures.ChatCompletionResponse`` is deprecated. This method will be removed in a future release. Use ``mlflow.types.llm.ChatCompletionResponse`` instead.\n  RagChatCompletionResponse(\nERROR:opentelemetry.context:Failed to detach context\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-d62d2718-7926-4fa9-91f6-cdecc3391974/lib/python3.10/site-packages/opentelemetry/context/__init__.py\", line 152, in detach\n    _RUNTIME_CONTEXT.detach(token)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-d62d2718-7926-4fa9-91f6-cdecc3391974/lib/python3.10/site-packages/opentelemetry/context/contextvars_context.py\", line 50, in detach\n    self._current_context.reset(token)  # type: ignore\nValueError: <Token var=<ContextVar name='current_context' default={} at 0x7f347026e1b0> at 0x7f345099cac0> was created in a different Context\nERROR:opentelemetry.context:Failed to detach context\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-d62d2718-7926-4fa9-91f6-cdecc3391974/lib/python3.10/site-packages/opentelemetry/context/__init__.py\", line 152, in detach\n    _RUNTIME_CONTEXT.detach(token)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-d62d2718-7926-4fa9-91f6-cdecc3391974/lib/python3.10/site-packages/opentelemetry/context/contextvars_context.py\", line 50, in detach\n    self._current_context.reset(token)  # type: ignore\nValueError: <Token var=<ContextVar name='current_context' default={} at 0x7f347026e1b0> at 0x7f344fc6dc00> was created in a different Context\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '**5 + 5 = 10**\\n\\nYou can verify this in Python using the following code:\\n```python\\nresult = 5 + 5\\nprint(result)  # Output: 10\\n```\\n\\n'}, 'finish_reason': 'stop'}], 'object': 'chat.completion'} ------------------------------------------------------------\n\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 12:10:39 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-d62d2718-7926-4fa9-91f6-cdecc3391974/lib/python3.10/site-packages/mlflow/langchain/output_parsers.py:46: FutureWarning: ``mlflow.models.rag_signatures.Message`` is deprecated. This method will be removed in a future release. Use ``mlflow.types.llm.ChatMessage`` instead.\"\n2025/01/22 12:10:39 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-d62d2718-7926-4fa9-91f6-cdecc3391974/lib/python3.10/site-packages/mlflow/langchain/output_parsers.py:46: FutureWarning: ``mlflow.models.rag_signatures.ChainCompletionChoice`` is deprecated. This method will be removed in a future release. Use ``mlflow.types.llm.ChatChoice`` instead.\"\n2025/01/22 12:10:39 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-d62d2718-7926-4fa9-91f6-cdecc3391974/lib/python3.10/site-packages/mlflow/langchain/output_parsers.py:45: FutureWarning: ``mlflow.models.rag_signatures.ChatCompletionResponse`` is deprecated. This method will be removed in a future release. Use ``mlflow.types.llm.ChatCompletionResponse`` instead.\"\n2025/01/22 12:10:39 INFO mlflow: Attempting to auto-detect Databricks resource dependencies for the current langchain model. Dependency auto-detection is best-effort and may not capture all dependencies of your langchain model, resulting in authorization errors when serving or querying your model. We recommend that you explicitly pass `resources` to mlflow.langchain.log_model() to ensure authorization to dependent resources succeeds when the model is deployed.\n/local_disk0/user_tmp_data/spark-d62d2718-7926-4fa9-91f6-cd/tmpae1jnwt8/model/model.py:332: FutureWarning: ``mlflow.langchain.output_parsers.ChatCompletionsOutputParser`` is deprecated. This method will be removed in a future release. Use ``mlflow.langchain.output_parser.ChatCompletionOutputParser`` instead.\n  agent = agent_with_raw_output | RunnableGenerator(wrap_output) | ChatCompletionsOutputParser()\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-d62d2718-7926-4fa9-91f6-cdecc3391974/lib/python3.10/site-packages/mlflow/langchain/output_parsers.py:46: FutureWarning: ``mlflow.models.rag_signatures.Message`` is deprecated. This method will be removed in a future release. Use ``mlflow.types.llm.ChatMessage`` instead.\n  choices=[ChainCompletionChoice(message=Message(role=\"assistant\", content=text))],\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-d62d2718-7926-4fa9-91f6-cdecc3391974/lib/python3.10/site-packages/mlflow/langchain/output_parsers.py:46: FutureWarning: ``mlflow.models.rag_signatures.ChainCompletionChoice`` is deprecated. This method will be removed in a future release. Use ``mlflow.types.llm.ChatChoice`` instead.\n  choices=[ChainCompletionChoice(message=Message(role=\"assistant\", content=text))],\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-d62d2718-7926-4fa9-91f6-cdecc3391974/lib/python3.10/site-packages/mlflow/langchain/output_parsers.py:45: FutureWarning: ``mlflow.models.rag_signatures.ChatCompletionResponse`` is deprecated. This method will be removed in a future release. Use ``mlflow.types.llm.ChatCompletionResponse`` instead.\n  RagChatCompletionResponse(\nERROR:opentelemetry.context:Failed to detach context\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-d62d2718-7926-4fa9-91f6-cdecc3391974/lib/python3.10/site-packages/opentelemetry/context/__init__.py\", line 152, in detach\n    _RUNTIME_CONTEXT.detach(token)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-d62d2718-7926-4fa9-91f6-cdecc3391974/lib/python3.10/site-packages/opentelemetry/context/contextvars_context.py\", line 50, in detach\n    self._current_context.reset(token)  # type: ignore\nValueError: <Token var=<ContextVar name='current_context' default={} at 0x7f347026e1b0> at 0x7f344fe604c0> was created in a different Context\nERROR:opentelemetry.context:Failed to detach context\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-d62d2718-7926-4fa9-91f6-cdecc3391974/lib/python3.10/site-packages/opentelemetry/context/__init__.py\", line 152, in detach\n    _RUNTIME_CONTEXT.detach(token)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-d62d2718-7926-4fa9-91f6-cdecc3391974/lib/python3.10/site-packages/opentelemetry/context/contextvars_context.py\", line 50, in detach\n    self._current_context.reset(token)  # type: ignore\nValueError: <Token var=<ContextVar name='current_context' default={} at 0x7f347026e1b0> at 0x7f344ffc04c0> was created in a different Context\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '**5 + 5 = 10**\\n\\nYou can verify this in Python using the following code:\\n```python\\nresult = 5 + 5\\nprint(result)  # Output: 10\\n```\\n\\n'}, 'finish_reason': 'stop'}], 'object': 'chat.completion'} ------------------------------------------------------------\n\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 12:11:08 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-d62d2718-7926-4fa9-91f6-cdecc3391974/lib/python3.10/site-packages/mlflow/langchain/output_parsers.py:46: FutureWarning: ``mlflow.models.rag_signatures.Message`` is deprecated. This method will be removed in a future release. Use ``mlflow.types.llm.ChatMessage`` instead.\"\n2025/01/22 12:11:08 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-d62d2718-7926-4fa9-91f6-cdecc3391974/lib/python3.10/site-packages/mlflow/langchain/output_parsers.py:46: FutureWarning: ``mlflow.models.rag_signatures.ChainCompletionChoice`` is deprecated. This method will be removed in a future release. Use ``mlflow.types.llm.ChatChoice`` instead.\"\n2025/01/22 12:11:08 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-d62d2718-7926-4fa9-91f6-cdecc3391974/lib/python3.10/site-packages/mlflow/langchain/output_parsers.py:45: FutureWarning: ``mlflow.models.rag_signatures.ChatCompletionResponse`` is deprecated. This method will be removed in a future release. Use ``mlflow.types.llm.ChatCompletionResponse`` instead.\"\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf76a511447e43b9b7d137344a6f627a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run delicate-panda-618 at: https://adb-1441223717721703.3.azuredatabricks.net/ml/experiments/3951031057998000/runs/a34e8c8d3c31495f8dd453d2254ffafc\nðŸ§ª View experiment at: https://adb-1441223717721703.3.azuredatabricks.net/ml/experiments/3951031057998000\n"
     ]
    }
   ],
   "source": [
    "# Log the model to MLflow\n",
    "import os\n",
    "import mlflow\n",
    "\n",
    "input_example = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the distance in miles between San Francisco and New York?\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.langchain.log_model(\n",
    "        lc_model=os.path.join(\n",
    "            os.getcwd(),\n",
    "            'agent',\n",
    "        ),\n",
    "        pip_requirements=[\n",
    "            \"langchain==0.2.16\",\n",
    "            \"langchain-community==0.2.16\",\n",
    "            \"langgraph-checkpoint==1.0.12\",\n",
    "            \"langgraph==0.2.16\",\n",
    "            \"pydantic\",\n",
    "            \"databricks_langchain\", # used for the retriever tool\n",
    "        ],\n",
    "        model_config=\"config.yml\",\n",
    "        artifact_path='agent',\n",
    "        input_example=input_example,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c71382e-e136-42bb-96fc-c59b11fd689c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Evaluate the agent with [Agent Evaluation](https://learn.microsoft.com/azure/databricks/generative-ai/agent-evaluation/)\n",
    "\n",
    "You can edit the requests or expected responses in your evaluation dataset and run evaluation as you iterate your agent, leveraging mlflow to track the computed quality metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfe17827-c8b1-4d59-aa02-754f910211ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "eval_examples = [\n",
    "    {\n",
    "        \"request\": {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"What is the distance in miles between San Francisco and New York?\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"expected_response\": None\n",
    "    }\n",
    "]\n",
    "\n",
    "eval_dataset = pd.DataFrame(eval_examples)\n",
    "display(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "909c5d93-74e1-404a-b0e7-f87c467be5ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "with mlflow.start_run(run_id=logged_agent_info.run_id):\n",
    "    eval_results = mlflow.evaluate(\n",
    "        f\"runs:/{logged_agent_info.run_id}/agent\",  # replace `chain` with artifact_path that you used when calling log_model.\n",
    "        data=eval_dataset,  # Your evaluation dataset\n",
    "        model_type=\"databricks-agent\",  # Enable Mosaic AI Agent Evaluation\n",
    "    )\n",
    "\n",
    "# Review the evaluation results in the MLFLow UI (see console output), or access them in place:\n",
    "display(eval_results.tables['eval_results'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "301b8bbd-c6d9-44c9-96ab-ce64e7fe7881",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register the model to Unity Catalog\n",
    "\n",
    "Update the `catalog`, `schema`, and `model_name` below to register the MLflow model to Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eaad1791-48a6-4579-8ab8-e677812e839c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# TODO: define the catalog, schema, and model name for your UC model\n",
    "catalog = \"main\"\n",
    "schema = \"default\"\n",
    "model_name = \"\"\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de5d3013-031a-46d5-b674-c9fc2bbb22dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Deploy the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "190d1ef1-ae18-4813-8cc9-fadecd84970c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "\n",
    "# Deploy the model to the review app and a model serving endpoint\n",
    "agents.deploy(UC_MODEL_NAME, uc_registered_model_info.version, tags = {\"endpointSource\": \"playground\"})"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "driver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}