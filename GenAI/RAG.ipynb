{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GenAI with Azure Databricks - Developing RAG System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the csv file into the DBFS (Databricks File System)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    " %sh\n",
    " rm -r /dbfs/rag_lab\n",
    " mkdir /dbfs/rag_lab\n",
    " wget -O /dbfs/rag_lab/diabetes_faq.csv https://raw.githubusercontent.com/kuljotSB/DatabricksUdemyCourse/refs/heads/main/GenAI/diabetes_treatment_faq.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the csv file into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "df = spark.read.load('/rag_lab/diabetes_faq.csv', format='csv', header=True)\n",
    "display(df.limit(10))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the openai SDK in our python kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai==1.56.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restarting our python kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Azure OpenAI Client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "openai_endpoint = \"<YOUR-AZURE-OPENAI-ENDPOINT>\"\n",
    "openai_key = \"<YOUR-AZURE-OPENAI-KEY>\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key = openai_key,\n",
    "    api_version = \"2024-02-15-preview\",\n",
    "    azure_endpoint = openai_endpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the updated/new dataframe into ADLS as parquet storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Save the updated DataFrame as a Parquet file or table\n",
    "df.write.mode(\"overwrite\").parquet(\"/rag_lab/diabetes_faq.parquet\")\n",
    "df_with_embeddings.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"<catalog_name>.default.diabetes_faq_table\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the databricks vectorsearch SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-vectorsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restarting our python environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developing the Cluster managed Vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "\n",
    "vector_client = VectorSearchClient()\n",
    "\n",
    "vector_client.create_endpoint(\n",
    "     name=\"vector_search_endpoint\",\n",
    "     endpoint_type=\"STANDARD\"\n",
    " )\n",
    "\n",
    "index = vector_client.create_delta_sync_index(\n",
    "   endpoint_name=\"vector_search_endpoint\",\n",
    "   source_table_name=\"<catalog_name>.default.diabetes_faq_table\",\n",
    "   index_name=\"<catalog_name>.default.diabetes_faq_index\",\n",
    "   pipeline_type=\"TRIGGERED\",\n",
    "   primary_key=\"Topic\",\n",
    "   embedding_source_column=\"Description\",\n",
    "   embedding_model_endpoint_name=\"databricks-gte-large-en\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triggering our Vector Index - Information Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "user_question = \"what is diabetes?\"\n",
    "\n",
    "results_dict = vector_index.similarity_search(\n",
    "            query_text = \"{user_question}\",\n",
    "            columns = [\"Topic\", \"Description\"],\n",
    "            num_results=1\n",
    "          )\n",
    "\n",
    "content = str(results_dict['result']['data_array'][0])\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developing the Generation Component of our RAG architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "gpt_response = client.chat.completions.create(\n",
    "                model=\"gpt-4\", # model = \"deployment_name\".\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant. You will be passed the user query and the supporting knowledge that can be used to answer the user_query\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"user query : {user_question} and supporting knowledge: {content}\"}\n",
    "                ]\n",
    "            )\n",
    "          print(gpt_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developing the RAG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow import pyfunc\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "class RAGModel(pyfunc.PythonModel):\n",
    "      def __init__(self, vector_index):\n",
    "          self.vector_index=vector_index\n",
    "      \n",
    "      def retrieve(self, query):\n",
    "          results_dict = self.vector_index.similarity_search(\n",
    "            query_text = query,\n",
    "            columns = [\"Topic\", \"Description\"],\n",
    "            num_results=1\n",
    "          )\n",
    "\n",
    "          return results_dict\n",
    "        \n",
    "      def chatCompletionsAPI(self, user_query, supporting_knowledge):\n",
    "          openai_client = AzureOpenAI(\n",
    "            azure_endpoint = \"<YOUR-AZURE-OPENAI-ENDPOINT>\",\n",
    "            api_key = \"<YOUR-AZURE-OPENAI-API-KEY>\",\n",
    "            api_version = \"2024-02-15-preview\"\n",
    "          )\n",
    "\n",
    "          response = openai_client.chat.completions.create(\n",
    "                model=\"YOUR_MODEL_NAME\", # model = \"deployment_name\".\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant. You will be passed the user query and the supporting knowledge that can be used to answer the user_query\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"user query : {user_query} and supporting knowledge: {supporting_knowledge}\"}\n",
    "                ]\n",
    "            )\n",
    "          return response.choices[0].message.content\n",
    "      \n",
    "      def predict(self, context, data):\n",
    "          query = data[\"query\"].iloc[0]\n",
    "          retrieved_docs = self.retrieve(query)\n",
    "          return self.chatCompletionsAPI(query, text_data)\n",
    "          \n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "test_model = RAGModel(vector_index=vector_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.models import infer_signature\n",
    "import pandas as pd\n",
    "\n",
    "signature = infer_signature(pd.DataFrame([{\"query\": \"what is diabetes?\"}]))\n",
    "model_path = \"RAGKULJOTmodel\"\n",
    "mlflow.pyfunc.save_model(path=model_path, python_model=test_model, signature=signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Our Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load our custom model from the local artifact store\n",
    "loaded_pyfunc_model = mlflow.pyfunc.load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our Loaded/Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_input = pd.DataFrame([{\"query\": \"what is diabetes?\"}])\n",
    "\n",
    "model_response = loaded_pyfunc_model.predict(model_input)\n",
    "\n",
    "print(model_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging our saved model as an artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Log the model as an artifact\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_artifacts(local_dir=model_path, artifact_path=\"rag_model\")\n",
    "    print(f\"Model logged with run ID: {run.info.run_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferencing the real-time endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "  \"dataframe_records\":[\n",
    "    {\n",
    "        \"query\":\"what is diabetes?\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
