{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Prediction Machine Learning Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset into the databricks file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " %sh\n",
    " rm -r /dbfs/ml_lab\n",
    " mkdir /dbfs/ml_lab\n",
    " wget -O /dbfs/ml_lab/diabetes.csv https://raw.githubusercontent.com/kuljotSB/DatabricksUdemyCourse/refs/heads/main/MachineLearningModel/diabetes.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring and Cleaning the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/ml_lab/diabetes.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "   \n",
    "data = df.dropna().select(col(\"Pregnancies\").astype(\"int\"),\n",
    "                           col(\"Glucose\").astype(\"int\"),\n",
    "                          col(\"BloodPressure\").astype(\"int\"),\n",
    "                          col(\"SkinThickness\").astype(\"int\"),\n",
    "                          col(\"Insulin\").astype(\"int\"),\n",
    "                          col(\"BMI\").astype(\"float\"),\n",
    "                          col(\"DiabetesPedigreeFunction\").astype(\"float\"),\n",
    "                          col(\"Age\").astype(\"int\"),\n",
    "                          col(\"Outcome\").astype(\"int\")\n",
    "                          )\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = data.randomSplit([0.7, 0.3])\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "print (\"Training Rows:\", train.count(), \" Testing Rows:\", test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing/scaling our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
    "\n",
    "numericFeatures = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\"]\n",
    "numericColVector = VectorAssembler(inputCols=numericFeatures, outputCol = \"numericFeatures\")\n",
    "vectorizedData = numericColVector.transform(train)\n",
    "\n",
    "minMax = MinMaxScaler(inputCol= numericColVector.getOutputCol(), outputCol=\"normalizedFeatures\")\n",
    "scaledData = minMax.fit(vectorizedData).transform(vectorizedData)\n",
    "\n",
    "compareNumerics = scaledData.select(\"numericFeatures\", \"normalizedFeatures\")\n",
    "display(compareNumerics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the features and the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preppedData = scaledData[col(\"normalizedFeatures\").alias(\"features\"), col(\"Outcome\").alias(\"label\")]\n",
    "display(preppedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10, regParam=0.3)\n",
    "model = lr.fit(preppedData)\n",
    "print (\"Model trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the prepared model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test data\n",
    "vectorizedTestData = numericColVector.transform(test)\n",
    "scaledTestData = minMax.fit(vectorizedTestData).transform(vectorizedTestData)\n",
    "preppedTestData = featVect.transform(scaledTestData)[col(\"featuresVector\").alias(\"features\"), col(\"Species\").alias(\"label\")]\n",
    "   \n",
    "# Get predictions\n",
    "prediction = model.transform(preppedTestData)\n",
    "predicted = prediction.select(\"features\", \"probability\", col(\"prediction\").astype(\"Int\"), col(\"label\").alias(\"trueLabel\"))\n",
    "display(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "   \n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "   \n",
    "# Simple accuracy\n",
    "accuracy = evaluator.evaluate(prediction, {evaluator.metricName:\"accuracy\"})\n",
    "print(\"Accuracy:\", accuracy)\n",
    "   \n",
    "# Individual class metrics\n",
    "labels = [0,1,2]\n",
    "print(\"\\nIndividual class metrics:\")\n",
    "for label in sorted(labels):\n",
    "    print (\"Class %s\" % (label))\n",
    "   \n",
    "    # Precision\n",
    "    precision = evaluator.evaluate(prediction, {evaluator.metricLabel:label,\n",
    "                                                evaluator.metricName:\"precisionByLabel\"})\n",
    "    print(\"\\tPrecision:\", precision)\n",
    "   \n",
    "    # Recall\n",
    "    recall = evaluator.evaluate(prediction, {evaluator.metricLabel:label,\n",
    "                                             evaluator.metricName:\"recallByLabel\"})\n",
    "    print(\"\\tRecall:\", recall)\n",
    "   \n",
    "    # F1 score\n",
    "    f1 = evaluator.evaluate(prediction, {evaluator.metricLabel:label,\n",
    "                                         evaluator.metricName:\"fMeasureByLabel\"})\n",
    "    print(\"\\tF1 Score:\", f1)\n",
    "   \n",
    "# Weighted (overall) metrics\n",
    "overallPrecision = evaluator.evaluate(prediction, {evaluator.metricName:\"weightedPrecision\"})\n",
    "print(\"Overall Precision:\", overallPrecision)\n",
    "overallRecall = evaluator.evaluate(prediction, {evaluator.metricName:\"weightedRecall\"})\n",
    "print(\"Overall Recall:\", overallRecall)\n",
    "overallF1 = evaluator.evaluate(prediction, {evaluator.metricName:\"weightedFMeasure\"})\n",
    "print(\"Overall F1 Score:\", overallF1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Pipeline for Encapsulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "   \n",
    "\n",
    "numFeatures = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\"]\n",
    "   \n",
    "# Define the feature engineering and model training algorithm steps\n",
    "numVector = VectorAssembler(inputCols=numFeatures, outputCol=\"numericFeatures\")\n",
    "numScaler = MinMaxScaler(inputCol = numVector.getOutputCol(), outputCol=\"normalizedFeatures\")\n",
    "featureVector = VectorAssembler(inputCols=[\"normalizedFeatures\"], outputCol=\"Features\")\n",
    "algo = LogisticRegression(labelCol=\"Species\", featuresCol=\"Features\", maxIter=10, regParam=0.3)\n",
    "   \n",
    "# Chain the steps as stages in a pipeline\n",
    "pipeline = Pipeline(stages=[ numVector, numScaler, featureVector, algo])\n",
    "   \n",
    "# Use the pipeline to prepare data and fit the model algorithm\n",
    "model = pipeline.fit(train)\n",
    "print (\"Model trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the pipline to inference prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.transform(test)\n",
    "predicted = prediction.select(\"Features\", \"probability\", col(\"prediction\").astype(\"Int\"), col(\"Species\").alias(\"trueLabel\"))\n",
    "display(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Decision Tree Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "   \n",
    "\n",
    "numFeatures = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\"]\n",
    "   \n",
    "# Define the feature engineering and model training algorithm steps\n",
    "numVector = VectorAssembler(inputCols=numFeatures, outputCol=\"numericFeatures\")\n",
    "numScaler = MinMaxScaler(inputCol = numVector.getOutputCol(), outputCol=\"normalizedFeatures\")\n",
    "featureVector = VectorAssembler(inputCols=[\"normalizedFeatures\"], outputCol=\"Features\")\n",
    "algo = DecisionTreeClassifier(labelCol=\"Species\", featuresCol=\"Features\", maxDepth=10)\n",
    "   \n",
    "# Chain the steps as stages in a pipeline\n",
    "pipeline = Pipeline(stages=[ numVector, numScaler, featureVector, algo])\n",
    "   \n",
    "# Use the pipeline to prepare data and fit the model algorithm\n",
    "model = pipeline.fit(train)\n",
    "print (\"Model trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "prediction = model.transform(test)\n",
    "predicted = prediction.select(\"Features\", \"probability\", col(\"prediction\").astype(\"Int\"), col(\"Species\").alias(\"trueLabel\"))\n",
    "   \n",
    "# Generate evaluation metrics\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "   \n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Species\", predictionCol=\"prediction\")\n",
    "   \n",
    "# Simple accuracy\n",
    "accuracy = evaluator.evaluate(prediction, {evaluator.metricName:\"accuracy\"})\n",
    "print(\"Accuracy:\", accuracy)\n",
    "   \n",
    "# Class metrics\n",
    "labels = [0,1,2]\n",
    "print(\"\\nIndividual class metrics:\")\n",
    "for label in sorted(labels):\n",
    "    print (\"Class %s\" % (label))\n",
    "   \n",
    "    # Precision\n",
    "    precision = evaluator.evaluate(prediction, {evaluator.metricLabel:label,\n",
    "                                                    evaluator.metricName:\"precisionByLabel\"})\n",
    "    print(\"\\tPrecision:\", precision)\n",
    "   \n",
    "    # Recall\n",
    "    recall = evaluator.evaluate(prediction, {evaluator.metricLabel:label,\n",
    "                                             evaluator.metricName:\"recallByLabel\"})\n",
    "    print(\"\\tRecall:\", recall)\n",
    "   \n",
    "    # F1 score\n",
    "    f1 = evaluator.evaluate(prediction, {evaluator.metricLabel:label,\n",
    "                                         evaluator.metricName:\"fMeasureByLabel\"})\n",
    "    print(\"\\tF1 Score:\", f1)\n",
    "   \n",
    "# Weighed (overall) metrics\n",
    "overallPrecision = evaluator.evaluate(prediction, {evaluator.metricName:\"weightedPrecision\"})\n",
    "print(\"Overall Precision:\", overallPrecision)\n",
    "overallRecall = evaluator.evaluate(prediction, {evaluator.metricName:\"weightedRecall\"})\n",
    "print(\"Overall Recall:\", overallRecall)\n",
    "overallF1 = evaluator.evaluate(prediction, {evaluator.metricName:\"weightedFMeasure\"})\n",
    "print(\"Overall F1 Score:\", overallF1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/models/diabetes.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Locally Inferencing our Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.pipeline import PipelineModel\n",
    "\n",
    "persistedModel = PipelineModel.load(\"/models/diabetes.model\")\n",
    "   \n",
    "newData = spark.createDataFrame ([{\"Pregnancies\": 8,\n",
    "                                  \"Glucose\": 85,\n",
    "                                  \"BloodPressure\": 65,\n",
    "                                  \"SkinThickness\": 29,\n",
    "                                  \"Insulin\": 0,\n",
    "                                  \"BMI\": 26.6,\n",
    "                                  \"DiabetesPedigreeFunction\": 0.672,\n",
    "                                  \"Age\": 34\n",
    "                                  }])\n",
    "   \n",
    "   \n",
    "predictions = persistedModel.transform(newData)\n",
    "display(predictions.select(\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\",  col(\"prediction\").alias(\"PredictedOutcome\")))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
